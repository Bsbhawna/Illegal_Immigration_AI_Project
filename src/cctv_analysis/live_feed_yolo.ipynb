{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96db98b3-fdf1-4fc5-ae22-b6cebfe7170d",
   "metadata": {},
   "source": [
    "# Live CCTV Simulation + YOLO Detection"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6f339984-c1e3-4dc4-b585-4c71801d0f8d",
   "metadata": {},
   "source": [
    "!pip install torch==1.13.1+cpu torchvision==0.14.1+cpu -f https://download.pytorch.org/whl/cpu/torch_stable.html\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a6ee734c-05e2-4f62-8665-c57c0b0d39b2",
   "metadata": {},
   "source": [
    "!pip install tqdm\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "062a6d88-32ac-4e66-af40-ddcebb6e801d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#  File: src/cctv_analysis/live_feed_yolo.py\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import winsound\n",
    "import csv\n",
    "\n",
    "# Set base directory\n",
    "base_dir = r\"C:\\Users\\sharmbha\\Downloads\\Bhawna_project\\Illegal_Immigration_AI_Project\"\n",
    "\n",
    "# Paths\n",
    "video_path = r'data/processed/cropped_footage.avi'\n",
    "output_video_path = r'data/final/final_alert_overlay.avi'\n",
    "log_csv_path = r'data/logs/alert_log.csv'\n",
    "sound_path = r'C:\\Users\\sharmbha\\Downloads\\Bhawna_project\\Illegal_Immigration_AI_Project\\data\\assets\\alert_sound.mp3'  # alert sound\n",
    "\n",
    "# Load YOLOv5 model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', force_reload=False)\n",
    "model.classes = [0]  # Detect only persons\n",
    "\n",
    "# Initialize video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "width, height = int(cap.get(3)), int(cap.get(4))\n",
    "out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'XVID'), 20.0, (width, height))\n",
    "\n",
    "# Logs\n",
    "logs = []\n",
    "frame_count, alert_count = 0, 0\n",
    "\n",
    "# Ensure the log file has headers if it doesn't exist\n",
    "if not os.path.exists(log_csv_path):\n",
    "    os.makedirs(os.path.dirname(log_csv_path), exist_ok=True)\n",
    "    with open(log_csv_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Timestamp\", \"Alert\", \"Frame\", \"Source\"])\n",
    "\n",
    "print(\"Starting video analysis...\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    results = model(frame)\n",
    "    detections = results.pandas().xyxy[0]\n",
    "    persons = detections[detections['name'] == 'person']\n",
    "\n",
    "    if not persons.empty:\n",
    "        alert_count += 1\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        # Draw bounding boxes\n",
    "        for _, row in persons.iterrows():\n",
    "            x1, y1, x2, y2 = int(row['xmin']), int(row['ymin']), int(row['xmax']), int(row['ymax'])\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "            cv2.putText(frame, 'ALERT: Person Detected', (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "\n",
    "        # Optional sound\n",
    "        if os.path.exists(sound_path):\n",
    "            try:\n",
    "                winsound.PlaySound(sound_path, winsound.SND_FILENAME | winsound.SND_ASYNC)\n",
    "            except Exception as e:\n",
    "                print(\"Sound error:\", e)\n",
    "\n",
    "        # Log to CSV (append one row per detection)\n",
    "        with open(log_csv_path, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([timestamp, \"Person Detected\", frame_count, \"live_feed\"])\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "print(f\"\\n YOLO Alert Video saved: {output_video_path}\")\n",
    "print(f\" Total Frames: {frame_count}, Alerts Triggered: {alert_count}\")\n",
    "print(f\" Log saved to: {log_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a0841ff-a644-4c02-8de7-3be554e218f2",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\sharmbha/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-4-16 Python-3.11.11 torch-2.6.0+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìΩÔ∏è Total Frames: 273\n",
      "üöÄ Starting video analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Video Frames: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 273/273 [01:22<00:00,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Output video saved at: C:\\Users\\sharmbha\\Downloads\\Bhawna_project\\Illegal_Immigration_AI_Project\\data/final/final_alert_overlay.avi\n",
      "üìä Total frames processed: 273\n",
      "üö® Total alerts triggered: 237\n",
      "üìù Log saved to: C:\\Users\\sharmbha\\Downloads\\Bhawna_project\\Illegal_Immigration_AI_Project\\data/logs/alert_log_live_feed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import winsound\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# === Paths and Setup ===\n",
    "base_dir = r\"C:\\Users\\sharmbha\\Downloads\\Bhawna_project\\Illegal_Immigration_AI_Project\"\n",
    "\n",
    "video_path = os.path.join(base_dir, 'data/processed/cropped_footage.avi')\n",
    "output_video_path = os.path.join(base_dir, 'data/final/final_alert_overlay.avi')\n",
    "log_csv_path = os.path.join(base_dir, 'data/logs/alert_log_live_feed.csv')  \n",
    "sound_path = os.path.join(base_dir, 'data/assets/alert_sound.mp3')\n",
    "\n",
    "# === Load YOLOv5 Model ===\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', force_reload=False)\n",
    "model.classes = [0]  # Only detect persons\n",
    "\n",
    "# === Load Video ===\n",
    "if not os.path.exists(video_path):\n",
    "    print(f\"‚ùå File does not exist: {video_path}\")\n",
    "    exit()\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    print(f\"‚ùå OpenCV could not open the video file. Check format or codec.\")\n",
    "    exit()\n",
    "\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "print(f\"üìΩÔ∏è Total Frames: {total_frames}\")\n",
    "\n",
    "# === Setup Video Writer ===\n",
    "out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'XVID'), 20.0, (frame_width, frame_height))\n",
    "\n",
    "# === Prepare Log File ===\n",
    "if not os.path.exists(log_csv_path):\n",
    "    os.makedirs(os.path.dirname(log_csv_path), exist_ok=True)\n",
    "    with open(log_csv_path, 'w', newline='') as file:\n",
    "        csv.writer(file).writerow([\"Frame\", \"Time (s)\", \"Timestamp\", \"Persons Detected\", \"Alert\"])\n",
    "\n",
    "print(\"üöÄ Starting video analysis...\")\n",
    "\n",
    "# === Analysis Loop ===\n",
    "alert_count = 0\n",
    "frame_count = 0\n",
    "\n",
    "with tqdm(total=total_frames, desc=\"Processing Video Frames\") as pbar:\n",
    "    while frame_count < total_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(f\"‚ö†Ô∏è End of video or error reading frame {frame_count}.\")\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "        results = model(frame)\n",
    "        detections = results.pandas().xyxy[0]\n",
    "        persons = detections[detections['name'] == 'person']\n",
    "\n",
    "        if not persons.empty:\n",
    "            alert_count += 1\n",
    "            timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "            # Draw bounding boxes\n",
    "            for _, row in persons.iterrows():\n",
    "                x1, y1, x2, y2 = map(int, [row['xmin'], row['ymin'], row['xmax'], row['ymax']])\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "                cv2.putText(frame, 'ALERT: Person Detected', (x1, y1 - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "\n",
    "            # Sound alert\n",
    "            if os.path.exists(sound_path):\n",
    "                try:\n",
    "                    winsound.PlaySound(sound_path, winsound.SND_FILENAME | winsound.SND_ASYNC)\n",
    "                except Exception as e:\n",
    "                    print(f\"üîá Sound error: {e}\")\n",
    "\n",
    "            # Log alert\n",
    "            frame_time_sec = round(cap.get(cv2.CAP_PROP_POS_MSEC) / 1000.0, 2)\n",
    "            with open(log_csv_path, 'a', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([\n",
    "                    frame_count,                     # Frame\n",
    "                    frame_time_sec,                 # Time (s)\n",
    "                    timestamp,                      # Timestamp\n",
    "                    len(persons),                   # Persons Detected\n",
    "                    \"Person Detected\"               # Alert\n",
    "                ])\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "# === Cleanup ===\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "print(f\"\\n‚úÖ Output video saved at: {output_video_path}\")\n",
    "print(f\"üìä Total frames processed: {frame_count}\")\n",
    "print(f\"üö® Total alerts triggered: {alert_count}\")\n",
    "print(f\"üìù Log saved to: {log_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef730cea-8fbd-475b-a1e4-f3c998f2f6e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
